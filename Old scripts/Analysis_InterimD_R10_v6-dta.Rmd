---
  output:
  pdf_document:
    includes:
      in_header: styles.tex
    number_sections: TRUE
    latex_engine: xelatex
    fig_caption: yes
    fig_width: 4
    fig_height: 3
    keep_tex: TRUE
header-includes:
  - \usepackage{titling}
  - \setlength{\droptitle}{5em} 
papersize: a4paper
fontsize: 11pt
mainfont: Calibri
geometry: margin = 3cm
subparagraph: TRUE
graphics: yes
bibliography: References.bib
csl: apa.csl
link-citations: yes
params:
  mainFile: ""
  intFile: ""

# European Social Survey - European Research Infrastructure (ESS-ERIC)
# europeansocialsurvey.org
# Notes
# Version: 6.0 standard
# Data format: STATA
---

```{r setup, include = FALSE, error=T}
library(knitr)
library(kableExtra)

knitr::opts_chunk$set(echo = FALSE, results = "hide", message = FALSE, dev = "cairo_pdf", warning = FALSE)
knitr::opts_chunk$set(fig.pos = 'H')

options(knitr.table.format = "latex", knitr.kable.NA = "")

Sys.setlocale("LC_ALL","English")

```

```{r setup2, include = FALSE, error=T}
#Installed packages
library(here) 
library(foreign)
library(dplyr)
library(psych)
library(ggplot2)
library(lubridate)
library(wesanderson)
library(colortools) # adjacent works
library(ggthemes) # theme_tufte works
library(varhandle) # coercing factor to numeric variables
library(naniar) # for replacing values with missings
library(knitr)
library(kableExtra)
library("Gifi") #Implements categorical principal component analysis
library(matrixStats) #High-performing functions operating on rows and columns of matrices
library(cowplot)
library(tibble)

#Utilities
source("Utility functions.R")
linebreak <- "\\hspace{\\textwidth}"
```

```{r theme, error=T}
ESSred <- rgb(.91, .20, .32)
ESSgreen <- rgb(.14, .62, .51)
ESSblue <- rgb(0, .25, .48)
  
ESSColors <- unique(c(adjacent(ESSred, plot = F), square(ESSred, plot = F)))

ESSColors <- c(ESSColors, ESSgreen, ESSblue)
# pizza(ESSColors)

themeESS <- theme_tufte(base_size = 9, base_family = "Calibri") +
    theme(axis.title = element_text(size = 9, face = "plain"),
          axis.text = element_text(size = 9),
          axis.line.x = element_line(),
          plot.title = element_blank(),
          legend.title = element_blank(),
          legend.text = element_text(size = 9),
          strip.text = element_text(size = 9, face = "bold"),
          legend.position = "none",
          legend.direction = "horizontal",
          legend.box = "vertical",
          legend.spacing = unit(0, "line"),
          legend.key.size = unit(.75, "line"))

```

\newpage
\FloatBarrier
\pagenumbering{gobble}

```{r child = "Titlepage.Rmd", error=T}
```

\pagenumbering{arabic}

\setcounter{tocdepth}{2}
\tableofcontents
\listoftables
\listoffigures

# Introduction {-}

```{r getdata, error=T}
# Interviewer-Questionnaire with Inwer ID (intnum):
Inwer <- foreign::read.dta(params$intFile, convert.factors=F)

# Main Dataset
Main <- foreign::read.dta(params$mainFile,convert.factors=F)

#Variable names to lower cases
names(Inwer) <- tolower(names(Inwer))
names(Main) <- tolower(names(Main))

Inwer_ID <- dplyr::select(Inwer, "intnum", "idno")
Main <- dplyr::left_join(Main, Inwer_ID, by = "idno")
```

```{r countrynames_rounds, error=T}
# this Country
Countrynames <- (read.csv2("Country names and codes.csv", dec = ".", stringsAsFactors = F))
Country <- as.data.frame(Main$cntry)
Country <- dplyr::rename(Country, cntry = 'Main$cntry')
Country <- left_join(Country, Countrynames, by = "cntry")

thisCountry <- unique(Country$CountryName)
```

```{r missingintnum, error=T}
# Allcases in Main
Mainfull <- Main

# Filter out cases without intnum
Main <- Main %>% filter(!is.na(intnum))
```

This report presents the results of the analysis of the interim dataset for `r thisCountry`. It aims to help national teams detecting undesirable interviewer behaviour. The report is divided into three sections. The first section presents the results on the analysis of the timestamps from the interview. The second section focuses on item non-response. The third section investigates response patterns of respondents and how these related to allocations within interviewers. Guidance as to how to interpret these results is also provided. 

It is recommended to  view these indicators as complementary to the information coming from the field. They help gain further insights into activities in the field. Indicators are complementary to each other as well.

It should also be noted that the analysis focused only on cases that have a valid interviewer number as it is assumed that all interviews have been conducted by an interviewer. Therefore, any case missing the interviewer number are not included in the analysis. The data provided to the tool contained a total of `r length(Mainfull$idno)` cases and a total of `r length(Main$idno)` contained a valid interviewer number.

Please feel free to contact your Country Contact or the ESS DIB team via myESS if you have any questions.


# Interview timestamps {#sec:timestamps}

```{r timestamps, error=T}
# fulldate for interviews
Main$fulldate <- as_datetime(Main$inwds, origin = "1960-01-01")
# fulldatetime for start and end of interview
Main$start <- as_datetime(Main$inwds, origin = "1960-01-01")
Main$end <- as_datetime(Main$inwde, origin = "1960-01-01")
# fulldatetime for modules
Main$end_a <- as_datetime(Main$ainwe, origin = "1960-01-01")
Main$end_b <- as_datetime(Main$binwe, origin = "1960-01-01")
Main$end_c <- as_datetime(Main$cinwe, origin = "1960-01-01")
Main$end_d <- as_datetime(Main$dinwe, origin = "1960-01-01")
Main$end_f <- as_datetime(Main$finwe, origin = "1960-01-01")
Main$end_g <- as_datetime(Main$ginwe, origin = "1960-01-01")
Main$end_h <- as_datetime(Main$hinwe, origin = "1960-01-01")
Main$end_i <- as_datetime(Main$iinwe, origin = "1960-01-01") 

```

In this section, indicators for detection of issues in interviewing process are drawn from the analysis of timestamps recorded for each interview (start and end of the interview, including timestamps for each module, and date and time of interview). Timestamps provide critical information about the conduction of the interview in the field and can help detect issues in the interviewing process. 

First, we look at the interview duration and interview speed on both the interview level and module level. Second, we analyze the time of the interview relative to the time of other interviews from the same interviewer. Please note that any issues highlighted require further investigation by the national teams.

Countries that follow the recommendation of including more detailed timestamps (e.g. timestamps per item) into their CAPI systems are able to conduct further analysis on those indicators. The ESS DIB team can provide further assistance if needed.

## Interview duration and interview speed {#sec:duration_speed}

Interview duration refers to the length of the interview excluding optional country-specific questions, the interviewer questions, and general administration of the contact procedures. Interview speed refers to the average speed (in terms of question per minute) in which the interview progresses. The average interview speed is calculated as the number of applicable questions for a specific respondent divided by the duration of the interview. It can be calculated at the interview level or another level, such as the module level (see \secref{sec:speed}).

Both duration and speed should be considered when assessing data quality. For example, extreme outliers in interview duration and/or interview speed can indicate a deviation from interviewing protocols (e.g. error in the recording of timestamps) or even falsification of interviews.

### Unlikely interview duration {#sec:duration}

Very short or very long interviews can be attributed to interviewer behaviour, but also to technical problems (e.g., software problems), atypical interviews, or respondent behaviour (e.g., partial interviews) [see @vandenplas2019, p. 252]. Detecting outliers can help identify systematic issues related to interviewers as a whole. Therefore, it is important to consider all interviews conducted by interviewers that have produced interviews with an unlikely duration. As mentioned before, very short of very long interview durations (i.e., outliers) could indicate a potential problem and in this analysis we define short interviews as interviews having lasted less than 30 minutes and long interviews as interviews having lasted 180 minutes or more.



```{r duration, error=T}
#interview period
Main$int_period <- Main$start %--% Main$end
# duration in minutes
Main$duration <- int_length(Main$int_period)/60
# interviewer with improbable low values
duration_30 <- dplyr::filter(Main, duration<30) 
duration_30_vec <- duration_30[, "intnum"]
# interviewer with improbable high values
duration_180 <- dplyr::filter(Main, duration>180) 
duration_180_vec <- duration_180[, "intnum"]
# vector with all suspicious interviewers in duration
duration_improb <- c(duration_30_vec, duration_180_vec)
# vector with duplicates in duration_improb
duration_improb_dup <- duration_improb[duplicated(duration_improb)]

# dataset only with improbable interviews
df_duration_improb <- bind_rows(duration_30, duration_180)
df_duration_improb$unlikely_duration <- ifelse(df_duration_improb$intnum %in% duration_30_vec & df_duration_improb$intnum %in% duration_180_vec, "both",
                                               ifelse(df_duration_improb$intnum %in% duration_30_vec, "<30",
                                                      ifelse(df_duration_improb$intnum %in% duration_180_vec, ">180", "none")))
df_duration_improb <- select(df_duration_improb, idno, intnum, unlikely_duration)
df_duration_improb_table <- df_duration_improb %>%
  dplyr::count(unlikely_duration, intnum)

# dataset with interviews between 0 and 240 minutes
df_duration <- Main %>% 
  group_by(intnum) %>%
  filter(duration<240) %>%
  mutate(duration_mean=mean(duration))
# order intnum by mean of duration per interviewer in filtered data set
df_duration$intnum <- factor(df_duration$intnum,
                             levels = unique(df_duration$intnum[order(df_duration$duration_mean)]))
df_duration$duration_improb <- ifelse(df_duration$intnum %in% duration_30_vec & df_duration$intnum %in% duration_180_vec, "both", 
                                      ifelse(df_duration$intnum %in% duration_30_vec, "<30",
                                             ifelse(df_duration$intnum %in% duration_180_vec, ">180", "none")))
duration_descr <- psych::describe(df_duration$duration, quant=c(.25,.75)) %>%
  select(mean, median, Q0.25, Q0.75)

```

In `r thisCountry` for `r ifelse(length(duration_improb)==0 , "no", length(duration_improb))` interviewer(s) at least one interview with unlikely short or long duration was detected. `r ifelse(length(duration_improb_dup)==0, "no", length(duration_improb_dup))` interviewer(s) had more than one outlier. An overview of the distribution of interview duration by interviewer can be seen in Figure \ref{fig:plot_duration}. Table \ref{tab:table_duration} shows the frequencies of an interview with unlikely duration per interviewer. For more details, see table in the annex folder with the interview duration per case and interviewer ("Interview duration.csv"). 

```{r duration_annex, error=T}

write.table(Main[,c("idno", "intnum", "int_period", "duration")], 
            "Annex/Interview duration.csv", sep = ";", row.names = F)

```


```{r duration_plot, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot_duration} Distribution of interview duration by interviewer (limits 0-240 minutes)",  linebreak, "Note: The figure shows only interviews with a duration of 0-240 minutes to give a better overview (see respective annex file for all interview duration records). Interviewers with at least one interview with a duration <30 or >180 minutes are labelled in the y axis with their interviewer ID. The vertical black lines represent the fences of unlikely interview duration (less than 30 and more than 180 minutes). The vertical blue line represents the mean of duration for all interviewers after deleting interviews with improbable durations."), fig.scap="Distribution of interview duration by interviewer", error=T}

        ggplot(df_duration, aes(duration, as.factor(intnum))) +
          geom_point(aes(colour = df_duration$duration_improb)) + 
          labs(x = "Interview duration (minutes; scale limited to range 0-240)",
               y = "Interviewers",
               color = "at least one interview\nwith duration <30 or >180") + 
          scale_colour_manual(values = c("both" = ESSColors[1],
                                         "<30" = ESSColors[2],
                                         ">180" = ESSColors[3],
                                         "none"= "grey")) +
          scale_x_continuous(breaks = seq(0, max(Main$intnum), 20)) + 
          scale_y_discrete(breaks = duration_improb) +
          theme(plot.caption = element_text(hjust = 0.5)) +
          geom_vline(xintercept = duration_descr$mean, color = wes_palette(n=1, name = "Zissou1")) +
          geom_vline(xintercept = 30) +
          geom_vline(xintercept = 180)

df_duration <- ungroup(df_duration)
```

```{r duration_table, results = "asis", error=T}
if(nrow(df_duration_improb_table)==0) {	
    kable("No interviewers with unlikely interview durations were detected", 	
      col.names = c(""), 	
      caption = paste("\\label{tab:table_duration} Interviewers with unlikely interview durations"))  %>%	
  kable_styling(latex_options = c("hold_position"))	
  } else { 	
    kable(df_duration_improb_table, 
      col.names = c("Duration","Interviewer ID", "Number of interviews"), 
      caption = paste("\\label{tab:table_duration} Interviewers with unlikely interview durations"))  %>%
  kable_styling(latex_options = c("hold_position")) %>%
  collapse_rows(columns = 1)
  }	
```

The general recommendation here is to go back to the survey agency (or fieldwork coordinator or interviewer in case of an in-house survey) and have them check these results with the interviewer in question. Especially in the case of interview duration, other indicators like speed and item non-response (see next sections) should be taken into consideration.

\newpage

### Interviewing speed {#sec:speed}

Previous research in the ESS has shown that the interview speed of interviews is linked to the impact interviewers have on the answers of the respondents, known as interviewer effects [@vandenplas2019]. Interviewer effects are measured by the extent to which the variance of items is explained by the allocation of cases within an interviewer. Vandenplas et al. [-@vandenplas2019] showed that there are larger interviewer effects for slow and for fast interviews compared to moderate interview durations. 

Due to filter questions in the ESS questionnaire, the number of applicable questions varies from interview to interview. Therefore, the speed of the interview provides a more comparable indicator across interviews. We calculate the speed over an interview $v$ as the number of applicable items in that interview $q$ divided by the time needed to complete the interview $t$ in minutes for each respondent $i$:

\begin{equation}
  \label{eq:speed}
  v_i=q_i/t_i
  \end{equation}
  
  
Equation \ref{eq:speed} indicates the number of items answered per minute. Interview speed can be calculated on the interview level and on the module level. Both can be informative when trying to assess the potential for undesirable interviewer behaviour. Below we provide you with an example as to how the estimated interview speed at the module level can aid us in detecting undesirable IB as well as help us in our understanding of potential mitigation strategies going forward.

**1. Interviewing speed on the module level: Module H**

```{r speed_H, error=T}

# Module H without improbable interview durations
Main_H <- dplyr::select(df_duration,c(idno, intnum, end_g, end_h, ipcrtiv:impfun))
# number of applicable items q_H
Main_H <- Main_H %>% mutate(q_H = rowSums(!is.na(select(., -c(intnum, idno, end_g, end_h)))))
# time needed to complete module t_H
Main_H <- Main_H %>% mutate(t_H = as.numeric(end_h - end_g)/60) %>%
  filter(t_H != 0)
# speed over a the module v_H
Main_H <- Main_H %>% mutate(v_H = q_H/t_H)
# average interviewer speed for all interviewers
Speed_H_all <- Main_H %>%
  group_by(intnum) %>%
  summarise(avg_speed=mean(v_H)) %>%
  mutate(group = "All interviewers")
# average interviwer speed for interviewers with at least 4 interviews
Speed_H_4 <- Main_H %>%
  group_by(intnum) %>%
  filter(n() > 3) %>%
  summarise(avg_speed=mean(v_H)) %>%
  mutate(group = "Interviewers with at least 4 interviews")

Speed_H <-bind_rows(Speed_H_all, Speed_H_4)

# flag ouliers

Speed_H <- Speed_H %>%
  #tibble::rownames_to_column(var="outlier") #%>%
  group_by(group) %>%
  mutate(is_outlier=ifelse(is_outlier(avg_speed), avg_speed, as.numeric(NA))) %>%
  mutate(intnum_out = intnum)
Speed_H$intnum_out[which(is.na(Speed_H$is_outlier))] <- as.numeric(NA)

```

Figure \ref{fig:plot_speed_H} shows the average interviewing speed for each interviewer and interviewers with at least four interviews for module H. We made this differentiation, because the probability that outliers in speed are incidental findings is lower for interviewers with at least four interviews. Interviews with unlikely interview durations (<30 minutes or >180 minutes) were excluded from the analysis because these are already detected in Section \ref{sec:duration} as outliers. We define an interviewing speed 1.5 times out of the Interquartilerange (IQR) as outliers with very fast or very slow interviewing speed. Those interviewers are labelled in the figure and listed together with their average interview speed in Table \ref{tab:table_speed_H}. For more details, see table in the annex folder with the interview speed for module H per case and interviewer ("Interview speed module H.csv"). 

```{r speed_H_annex, error=T}

write.table(Main_H[,c("idno", "intnum", "v_H")] %>% dplyr::rename(speed = v_H), 
            "Annex/Interview speed module H.csv", sep = ";", row.names = F)
```


```{r speed_H_plot, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot_speed_H} Average interviewing speed for Module H",  linebreak, "Note: Interviewing speed is defined as items answered per minute. The squares represent the mean of the distribution. Interviewers that are  > 1.5*IQR from the borders of the box are labelled."), fig.scap="Average interviewing speed for Module H", error=T}

ggplot(Speed_H, aes(x=group, y=avg_speed, fill=group)) +
  geom_boxplot() +
  stat_summary(fun = mean, geom = "point", shape=23, size=4) +
  scale_fill_manual(values = c(ESSColors[3], ESSColors[4])) +
  geom_text(aes(label=intnum_out), na.rm=TRUE, nudge_y=0.05, hjust = -0.3) +
  theme(legend.position="none") + 
  labs(x = "",
       y = "Interview speed")

```

```{r speed_H_table, results = "asis", error=T}
if(all(is.na(Speed_H$is_outlier))==T) {	
    kable("No interviewers with unlikely interview speed were detected", 	
      col.names = c(""), 	
      caption = paste("\\label{tab:table_speed_H} Interviewers with unlikely interview speed"))  %>%	
  kable_styling(latex_options = c("hold_position"))	
  } else { 	
  kable(na.omit(Speed_H[c("group", "intnum", "is_outlier")]), 	
      col.names = c("Group","Interviewer ID", "Average speed"), 	
      caption = paste("\\label{tab:table_speed_H} Interviewers with unlikely interview speed"))  %>%	
  kable_styling(latex_options = c("hold_position")) %>%	
  collapse_rows(columns = 1)	
  }

```

A very high interview speed should give rise to further investigation as to how these interviewers conducted these modules. It is advisable to go back and ask what exactly happened there. In general terms: Module H is the last questionnaire module and there could be some unfortunate, but valid reasons as to why some of the interviews were conducted with this average speed (e.g., respondent broke off the interview so the interviewer coded all remaining answers as 'no answer'). However, it is of course of particular interest if this pattern is observed multiple times within the same interviewer as this may indicate a more systematic undesirable behaviour such as rushing through the questions, not reading these questions to the respondent, or not challenging the respondent when he/she does not differentiate anymore.

\newpage

## Interview time {#sec:int_times}

The (date and) time in which the interviews were conducted is another indicator that has proven useful for detecting undesirable interviewer behaviour or other issues in the field. It can inform about compliance with contacting and interviewing protocol, performance in achieving the respondent's cooperation, as well as error in the recording of timestamps. First, we look at interviews with an overlapping interview time conducted by the same interviewer. Second, the time of the day in which interviews were conducted is checked for unlikely interview hours (e.g., the middle of the night). Third, we look at the number of interviews conducted on the same day by the same interviewer. Lastly, the time between consecutive interviews of the same interviewer is analysed and its plausibility assessed.

### Overlaps of interview time {#sec:overlaps}

```{r overlaps, error=T}
# overlap of two time periods
Main <- mutate(Main, interval = lubridate::interval(start, end))  
Inw_Overlap <- dplyr::arrange(Main, intnum) #needs to be sorted by intnum for next stage to work
Inw_Overlap$overlap <- unlist(tapply(Inw_Overlap$interval, #loop through Intervals
                                     Inw_Overlap$intnum, #grouped by id
                                     function(x) rowSums(outer(x, x, int_overlaps))>1))
Inw_Overlap <- dplyr::select(Inw_Overlap, "intnum", "idno", "cntry", "overlap")
Main <- dplyr::left_join(Main, Inw_Overlap, by = c("intnum", "idno", "cntry"))
Inw_Overlap <- filter(Main, overlap==T)
# vector with all suspicious interviewers in Inw_Overlap
inw_overlap <- dplyr::pull(Inw_Overlap, intnum)
# vector with duplicates in duration_overlap
inw_overlap_dup <- inw_overlap[duplicated(inw_overlap)]
# check, which are the reasons for overlapping interview-times
Inw_Overlap_doc <- dplyr::select(Main, "intnum", "idno", "cntry", "interval", "overlap")
Inw_Overlap_doc <- Inw_Overlap_doc %>% arrange(intnum, interval)
```

The overlap of the interview time of different interviews conducted by the same interviewer is an implausible outcome of fieldwork activities and could indicate the occurrence of poor interviewer behaviour. Overlapping times could be the result of interviewer deviating from interviewing protocol (e.g. entering the wrong interview time manually, forgetting to close the CAPI application, or multiple interviewers conducting interviews under the same ID). Moreover, it could be the result of interview falsification (e.g. fabrication of full interviews or parts of the interviews). 

However, before jumping to these serious conclusions, it is important to realize that overlapping interview times can also be the result of technical CAPI issues. These are serious issues which should be corrected on time to avoid contamination or the loss of data, but they are not necessarily the result of undesirable interviewer behaviour. Still, if an overlapping of interview times is detected, it is necessary to look up the causes. The national team should investigate the cases in detail to clarify the reasons of occurrence. Please also inform the CST about the outcome of further investigation of these cases.

In `r thisCountry` an overlap in interview times analysis was conducted and it revealed `r ifelse(length(inw_overlap)==0, "no", length(inw_overlap))` cases(s) of overlap with `r ifelse(length(unique(inw_overlap))==0, "no", length(unique(inw_overlap)))` interviewer(s) having overlapping cases `r ifelse(length(unique(inw_overlap))==0, "", paste(c("(intnum =", unique(inw_overlap), ")"), collapse= " ") )`. Please inform the CST about the outcome of further investigation of these cases.

```{r overlap_annex, error=T}

#Annex file with flags
write.table(Inw_Overlap_doc,
            "Annex/Interview overlap.csv", sep = ";", row.names = F)

```

\newpage

### Time of interview {#sec:time}

We expect most of the interviews to take place during daily hours of social life because that is when potential respondents would accept an invitation to conduct an interview as well as that these hours would correspond with the 'regular' working hours of an interviewer. We would view interviews with a starting time between 10 pm and 6 am and/or ending between 11 pm and 7 am as unlikely. It is possible to conduct interviews during these hours, but they should be looked into more detail. This indicator could inform about possible issues in the data collection or the recording of timestamps, but one should of course take notice of socially accepted interview times in a particular country. However, if multiple interviews from the same interviewer have taken place at an unlikely time, we highly recommend conducting back-checks on these cases.

```{r time, error=T}
Main$inwshh <- as.integer(hour(Main$start))
Main$inwehh <- as.integer(hour(Main$end))
Inw_times <- Main %>%
	  filter(inwshh<=6 | inwshh>=22 | inwehh<=7 | inwehh>=23)	
Inw_times_start <- Main %>%	
  filter(inwshh<=6 | inwshh>=22)	
Inw_times_end <- Main %>%	
  filter(inwehh<=7 | inwehh>=23)
# vector of all interviewers with improbable interview times	
inw_times <- dplyr::pull(Inw_times, intnum)	
inw_times_start <- dplyr::pull(Inw_times_start, intnum)	
inw_times_end <- dplyr::pull(Inw_times_end, intnum)	
# vector with duplicates in inw_times	
inw_times_dup <- inw_times[duplicated(inw_times)]	
# Flag unlikey time	
Main$unlikitm <- ifelse(Main$intnum %in% Inw_times$intnum, "unlikely", "likely")	
Main$unlikstm <- ifelse(Main$inwshh<=6 | Main$inwshh>=22, "unlikely", "likely")	
Main$unliketm <- ifelse(Main$inwehh<=7 | Main$inwehh>=23, "unlikely", "likely")
#Flags only for annex
Main$unlikelystart <- ifelse(Main$inwshh<=6 | Main$inwshh>=22, "unlikely start time", "")
Main$unlikelyend <- ifelse(Main$inwehh<=7 | Main$inwehh>=23, "unlikely end time", "")
```	

```{r time_fig, fig.show="hold", out.width="50%", error=T}	
# Timers in hours	
Main$starttm <- (as.numeric(Main$start - floor_date(Main$start, "1 day"), unit="secs")/3600)	
Main$endtm  <- (as.numeric(Main$end - floor_date(Main$end, "1 day"), unit="secs")/3600)	
# Plot start and end separatly	
# Plot start of interview	
ggplot(Main, aes(starttm, as.factor(intnum))) + 	
  geom_point(aes(colour = Main$unlikstm)) + 	
  labs(y = "Interivewers",	
               y = "Interviewers",	
               color = "Group") +	
  scale_colour_manual(values = c("unlikely" = ESSColors[1],	
                                         "likely"= "grey")) +	
  scale_x_continuous(name="Hours of day", limits=c(0, 24), breaks = seq(0,24,1)) + 	
  scale_y_discrete(breaks = inw_times_start) +	
  theme(plot.caption = element_text(hjust = 0.5)) +	
  geom_vline(xintercept = 7, color = "grey45") +	
  geom_vline(xintercept = 22, color = "grey45") +	
  ggtitle ("Start of Interview")	
# Plot end of interview	
ggplot(Main, aes(endtm, as.factor(intnum))) + 	
  geom_point(aes(colour = Main$unliketm)) + 	
  labs(y = "Interviewers",	
               y = "Interviewers",	
               color = "Group") +	
  scale_colour_manual(values = c("unlikely" = ESSColors[1],	
                                         "likely"= "grey")) +	
  scale_x_continuous(name="Hours of day", limits=c(0, 24), breaks = seq(0,24,1)) + 	
  scale_y_discrete(breaks = inw_times_end) +	
  theme(plot.caption = element_text(hjust = 0.5)) +	
  geom_vline(xintercept = 8, color = "grey45") +	
  geom_vline(xintercept = 23, color = "grey45") +	
  ggtitle ("End of Interview")

```

```{r time_annex, error=T}

#Annex file with flags
write.table(Main[,c("idno", "intnum", "start", "unlikelystart", "end", "unlikelyend")],
            "Annex/Interview start and end time.csv", sep = ";", row.names = F)

```

In `r thisCountry`, unlikely interview times were `r ifelse(length(inw_times)==0, "not detected for any interviewer", paste("detected for", length(inw_times), "case(s)"))` `r ifelse(length(unique(inw_times))==0, "", paste(c("(intnum =", unique(inw_times), ")"), collapse= " ") )`. The figure shows the distribution of time interviewer started and ended their interviews. For more details, see table in the annex folder with the time for the start and end of the interviews ("Interview start and end time.csv").


### Number of interviews on the same day by a single interviewer {#sec:number_int}

The maximum number of interviews in a single day by a single interviewer is an indicator of peak performance by an interviewer. Interviewers should organize and schedule their contact attempts and appointments in such a way that allows them to work as efficiently as possible. However, in some cases, this peak performance indicator can be related to non-compliance with contacting, selection or interviewing protocols. Therefore, national teams are recommended to closely monitor the work of interviewers with an extremely high number of completed interviews within a single day. 

```{r number_int, error=T}
#Get date from datetime
Main$date <- as.Date(Main$fulldate, format = "%Y-%m-%d")
# n>3 interviews on the same day, indicator: ninw_day
Ninw_day <- Main %>% 
  group_by(intnum, date) %>% 
  dplyr::count(.) %>%
  filter(n>3)
# vector of all interviewers with >3 interviews per day
ninw_day <- dplyr::pull(Ninw_day, intnum)
# vector with duplicates in ninw_day
ninw_day_dup <- ninw_day[duplicated(ninw_day)]
```

In `r thisCountry` fieldwork data revealed that in `r ifelse(length(ninw_day)==0, "no", length(ninw_day))` `r ifelse(length(ninw_day)==0 | length(ninw_day)==1, "case", "cases")` interviewers achieved more than three interviews per day. For more details, see table in the annex folder with the maximum number of interviews per day achieved by each interviewer ("Maximum interview per day.csv"). As mentioned before it is entirely possible to conduct this many interviewers on a single day. Please adjust this threshold of three interviews if is appropriate for your country. These adjustments should be discussed with the CST. If the threshold was reached for more than one case, we would recommend back-checking these interviewers if, in conjunction with the time interval indicator (see \secref{sec:interval}), the combination becomes improbable.


```{r number_int_annex, error=T}

Number_int <- Main %>% 
  group_by(intnum, date) %>% 
  dplyr::count(.) %>%
  dplyr::rename(number_int = n)

write.table(Number_int, 
            "Annex/Maximum interview per day.csv", sep = ";", row.names = F)

```


### Time interval between consecutive interviews by a single interviewer {#sec:interval}

The time between consecutive interviews by a single interviewer could also be an indicator of non-compliance with contacting and selection protocol or poor interviewer behaviour. Similar to the number of interviews of on the same day, interviewer should organize and schedule their contact attempts and appointments in such a way that allows them to optimize the (travel)time between interviews. However, extremely short time intervals could also indicate issues affected by undesirable interviewer behaviour, especially if these occur multiple times within the workload of a single interviewer. 

To this end, the analyses would show the minutes between the end of an interview and the start of the following interview within each interviewer. In many cases, the resulting number of minutes is very large, e.g., because the following interview took place another day. Whenever multiple interviews took place on the same day, it is more relevant to check the interval between two interviews.

```{r interval, error=T}
# time (in minutes) between 2 interviews within interviewers (start[t] - end[t-1])
dftime <- dplyr::arrange(Main, intnum, start) # dataframe needs to be sorted by intnum and start for next stage to work
dftime <- dftime %>%
            group_by(intnum) %>%
            mutate(diff = start - lag(end),
                    timebtwints = as.numeric(diff, units = 'mins'))
dftime <- dplyr::select(dftime, "intnum", "idno", "cntry", "start", "end", "timebtwints")
dftime <- dftime %>% mutate(timebtwints_critical = if_else(timebtwints <= 30, T, F)) # mark all cases with a critical time between interviews of less than 30 minutes
timebtwints_critical <- filter(dftime, timebtwints_critical==T)
dftime_critical <- unique(timebtwints_critical[['intnum']])

dftime_120 <- filter(dftime, timebtwints>=0 & timebtwints <= 120)
```

Figure \ref{fig:plot_interval} lists interviewers with interviews for which the previous interview was conducted 120 minutes ago or less. Shorter and potentially critical intervals of less than 30 minutes are highlighted in orange to allow an easy check of patterns and clusters. As for most timestamp indicators, this figure can be a good starting point to check the underlying reasons with the survey agency and highlighted interviewers. In `r thisCountry`, an interval time between two consecutive interviews of less than 30 minutes `r ifelse(nrow(timebtwints_critical)==0, "did not occur", paste("occurred", nrow(timebtwints_critical), "times"))`. For more details, see table in the annex folder with the time interval between interviews of the same interviewer ("Time interval between interviews.csv"). 

```{r interval_annex, error=T}

write.table(dftime[,c("idno", "intnum", "start", "end", "timebtwints")], 
            "Annex/Time interval between interviews.csv", sep = ";", row.names = F)

```


```{r interval_plot, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot_interval} Time interval between consecutive interviews by interviewer",  linebreak, "Note: For a better overview, only intervals <= 120 minutes were considered in the graph. Interviewer with at least one interval < 30 minutes are labelled."), fig.scap="Time interval between consecutive interviews by interviewer", error=T}

ggplot(dftime_120, aes(timebtwints, as.factor(intnum))) +
          geom_point(aes(colour = dftime_120$timebtwints_critical)) + 
          labs(x = "Time between interviews (minutes)",
               y = "Interviewers",
               color = "interval <30 minutes \nbetween consecutive \ninterviews") + 
          scale_colour_manual(values = c("FALSE" = "grey",
                                         "TRUE" = ESSColors[2])) +
          scale_x_continuous(breaks = seq(0, max(Main$intnum), 20)) + 
          scale_y_discrete(breaks = dftime_critical) +
          theme(plot.caption = element_text(hjust = 0.5))
```

# Item-Nonresponse {#sec:nonresponse}

This section focuses on item-nonresponse on the interviewer level for the participating ESS countries. In this section, we will take the variable income and module H to study (the proportion of) nonresponse per interviewer in `r thisCountry`. Nonresponse is in this section defined by either giving the item response "Refusal", "Don't know", or "No answer". 

The proportion of nonresponse per interviewer is given by the number of the selected part of interviews that elicited a nonresponse divided by the total number of interviews held by the interviewer in question. Whereas a low or high proportion of item-nonresponse is not necessarily a sign of misconduct, sloppiness or any wrongdoing on the interviewer's part, it might be insightful to study item-nonresponse nonetheless. A reason for further investigation might be if the proportion of missing values within an interview is unusual in conjunction with other unusual patterns in the data for this particular interview, especially if this pattern is observed within multiple interviews conducted by the same interviewer. For instance, a high proportion of item-nonresponse combined with unusual interview duration might give us some reason to worry because this may indicate that an interviewer skipped sections of the questionnaire during the interview. We would like to warn NCs that in isolation an unusual proportion of item-nonresponse is not enough ground to flag an interviewer as a suspicious case.
 
In the remainder of this section, we will give an overview of average item-nonresponse, and item-nonresponse on the interviewer level for the selected variables.

## Item-nonresponse for the variable income {#sec:nr_income}

The decision to zoom in on item-nonresponse for the variable *income* stems from the sensitive nature of this question. Discussing someone's income is taboo in many cultures and nonresponse on an item like this is typically high [@tourangeau2007]. Therefore, it seems unlikely to find very low item-nonresponse on this item, and even more unlikely if this pattern is observed on many interviews conducted by the same interviewer. However, the degree to which this question elicits a nonresponse may vary from culture to culture. This should be considered when interpreting the results.

We start with an overview of the occurrence of item-nonresponse in `r thisCountry`, to obtain some insight on the degree to which item-nonresponse is common within the country. Then we proceed to investigate unusual patterns in the data regarding nonresponse on the *income* item between interviewers.

For an overview, we, firstly, check the percentages of nonresponse on the *income* item. Secondly, we summarize the proportion of item-nonresponse on the *income* item of all interviews conducted by the same interviewer. The proportion of item-nonresponse $p$ on the *income* item for each interviewer $j$ is calculated as follows:

\begin{equation}
  \label{eq:nr_income}
  p_j=inr_j/ni_j
  \end{equation}

where $inr_j$ gives the number of interviews in which a respondent gave a nonresponse on the *income* item for interviewer $j$ and $ni_j$ the total number of interviews conducted by interviewer $j$.

```{r nr_income, error=T}
### Create variables of interest: missingness per interviewer  ###         
  # table scores for variable income                    
    inc.mis <- Main %>%  
                dplyr::select(intnum, hinctnta) %>%
                group_by(intnum) %>%
                table()
    inc.mis.all <- as.data.frame(unclass(inc.mis))
    inc.mis.all <- tibble::rownames_to_column(inc.mis.all, var = "intnum")
    inc.mis.all$intnum <- as.numeric(inc.mis.all$intnum)

  # add 99 as potential outcome to data.frame
    help <- inc.mis.all %>%
      select(intnum) %>%
      mutate("99" = 0)
    inc.mis.all <- left_join(inc.mis.all, help)

  # How many values (i.e., interviews) per interviewer?  
    inc.mis.all <- mutate(inc.mis.all, num.int = rowSums(inc.mis.all[, -1]))
    # num.int <- rowsum(inc.mis)
  
  # Number of missings (either refusal or don't know) 
    inc.mis.all <- mutate(inc.mis.all, num.mis = rowSums(inc.mis.all[,c("77", "88", "99")]))
    # num.mis <- rowSums(inc.mis[,c("77", "88", "99")])
    inc.mis.all <- mutate(inc.mis.all, prop.mis = num.mis/num.int)
    # prop.mis <- num.mis/num.int # proportion
```

In `r thisCountry` the percentage of nonresponse for the variable income is `r round(sum(Main$hinctnta==77|Main$hinctnta==88|Main$hinctnta==99)/nrow(Main), 4)*100`%: `r round(sum(Main$hinctnta==77)/nrow(Main), 4)*100`% of these nonresponses were refusals, `r round(sum(Main$hinctnta==88)/nrow(Main), 4)*100`% don't knows and `r round(sum(Main$hinctnta==99)/nrow(Main), 4)*100`% no answers. In this dataset `r nrow(inc.mis.all)` interviewers completed at least one interview. On average, each of those interviewers conducted `r round(mean(inc.mis.all$num.int), 2)` interviews, with half of all interviewers conducting at least `r round(median(inc.mis.all$num.int), 2)` interviews. The minimum number of interviews per interviewer is `r round(min(inc.mis.all$num.int), 2)`, the maximum number `r round(max(inc.mis.all$num.int), 2)`. Figure \ref{fig:plot1_nr_income} shows the distribution of the proportion of item-nonresponse in the variable income, calculated according to Equation \ref{eq:nr_income} separately for all interviewers and interviewers with at least 10 interviews.

Overall, we can expect the proportions of nonresponse per interviewer to be relatively low, but there might be some exceptions. Looking at all interviewers, we can expect some extreme proportions for interviewers who conducted only one or a few interviews. For a better overview, the distribution of interviewers with at least 10 interviews should therefore also be considered.

```{r nr_income_plot1, fig.height = 5, fig.width = 7, fig.cap = paste("\\label{fig:plot1_nr_income} Proportion of item-nonresponse in income per interviewer",  linebreak, "Note: The red line indicates the mean of the proportion. The blue line indicates the median."), fig.scap= "Proportion of item-nonresponse in income", error=T}

p1 <- ggplot(inc.mis.all, aes(prop.mis)) + 
  geom_histogram(fill=ESSColors[4]) +
  labs(x="Proportion (all interviewers)", y = "Frequency") +
  geom_vline(aes(xintercept=mean(prop.mis)),
            color=ESSColors[1], size=1) +
  geom_vline(aes(xintercept=median(prop.mis)),
            color=ESSColors[5], size=1)

p2 <- ggplot(subset(inc.mis.all, num.int > 9), aes(prop.mis)) + 
  geom_histogram(fill=ESSColors[4]) +
  labs(x="Proportion \n(interviewers with at least 10 interviews)", y = "Frequency") +
  geom_vline(aes(xintercept=mean(prop.mis)),
            color=ESSColors[1], size=1) +
  geom_vline(aes(xintercept=median(prop.mis)),
            color=ESSColors[5], size=1)

plot_grid(p1, p2 + theme(legend.title = element_text(face = "bold"), legend.position = "bottom", legend.direction = "vertical", axis.line.x = element_line()), 
          ncol = 2)
```

\newpage

For interviewers who conducted many interviews, we expect there to be some, but not a lot of nonresponses. To find unusual proportions of item-nonresponse, we need to zoom in on interviewers who conducted a fair number of interviews, and who have either a very low or a high proportion of nonresponse.

```{r nr_income_unusual, error=T}

  inc.mis.all$group <- as.factor(rep("All interviewers", nrow(inc.mis.all)))
  inc.mis.9i <- subset(inc.mis.all, inc.mis.all$num.int>9)
  inc.mis.9i$group <- as.factor(rep("Interviewers with at least 10 interviews", nrow(inc.mis.9i)))
  inc.mis <-bind_rows(inc.mis.all, inc.mis.9i)
  
  # Flag outliers
  inc.mis <- inc.mis %>%
    #tibble::rownames_to_column(var="outlier") #%>%
    group_by(group) %>%
    mutate(is_outlier=ifelse(is_outlier(as.numeric(prop.mis)), as.numeric(prop.mis), as.numeric(NA))) %>%
    mutate(intnum_out = intnum)
    inc.mis$intnum_out[which(is.na(inc.mis$is_outlier))] <- as.numeric(NA)
    
# Subset with Interviewers with at least ten interviews and a proportion of item-nonresponse larger than 50%
inc.mis.50 <- inc.mis.all %>%
  subset(prop.mis>.50 & num.int > 9) %>%
  select(intnum, num.int, prop.mis)

# Subset with Interviewers with at least ten interviews and a proportion of item-nonresponse smaller than 1%
inc.mis.01 <- inc.mis.all %>%
  subset(prop.mis<.01 & num.int > 9) %>%
  select(intnum, num.int, prop.mis)
```

Figure \ref{fig:plot_nr_income_unusual} gives an overview of outliers in proportion  of nonresponse, both for the complete sample and for the subset of interviewers who conducted 10 interviews or more. For more details, see table in the annex folder with the proportion of item nonresponse per interviewer for income ("Prop item nonresponse income.csv"). We particularly recommend looking at interviewers who have conducted 10 or more interviews and had a proportion of nonresponse larger than 50%. Because nonresponse is common for the variable income, very little or no nonresponse might also be unusual and worthy of our attention. Those interviewers might be investigated more, but should not be flagged solely on this data. 

```{r nr_income_annex, error=T}

Prop_nr_income <- inc.mis %>% 
  filter(group == "All interviewers") %>% 
  select(intnum, prop.mis, num.int)
Prop_nr_income <- Prop_nr_income[, c("intnum", "prop.mis", "num.int")]

write.table(Prop_nr_income,
            "Annex/Prop item nonresponse income.csv", sep = ";", row.names = F)

```


```{r nr_income_unusual_plot, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot_nr_income_unusual} Proportion of item-nonresponse in income with labelled outliers",  linebreak, "Note: The squares represent the mean of the distribution. Interviewers that are  > 1.5*IQR from the borders of the box are defined as outliers."), fig.scap="Proportion of item-nonresponse in income with labelled outliers", error=T}

ggplot(inc.mis, aes(x=group, y=prop.mis, fill=group)) + 
    geom_boxplot() +
    stat_summary(fun = mean, geom = "point", shape=23, size=4) +
    scale_fill_manual(values = c(ESSColors[3], ESSColors[4])) +
    geom_text(aes(label=intnum_out), na.rm=TRUE, hjust = -0.3) +
    theme(legend.position="none") + 
    labs(x = "",
         y = "Proportion nonresponse")
```

\newpage

## Item-nonresponse for Module H {#sec:nr_moduleH}

In addition to studying item-nonresponse for a sensitive question like income, we additionally aim our attention at the patterns of nonresponse in a module of less sensitive questions, in this case, *Module H* (21 items). Again, we first give an overview of item-nonresponse on the items in *Module H* in `r thisCountry`, and in the second part, we zoom in on unusual properties.

For an overview, we, firstly, check the percentages of nonresponse on the items in *Module H*. Secondly, we summarize the proportion of item-nonresponse on items in *Module H* of all interviews conducted by the same interviewer. The proportion of item-nonresponse $p$ on items in *Module H* for each interviewer $j$ is calculated according to Equation \ref{eq:nr_income}. Subsequently, for each interviewer, we calculate the mean proportion of item-nonresponse over these 21 items.

```{r nr_moduleH, error=T}

# Selection of variables module Human Values
  hvc <- c("ipcrtiv", "imprich", "ipeqopt", "ipshabt", "impsafe", "impdiff", 
           "ipfrule", "ipudrst", "ipmodst", "ipgdtim", "impfree", "iphlppl",
           "ipsuces", "ipstrgv", "ipadvnt", "ipbhprp", "iprspot", "iplylfr",
            "impenv", "imptrad", "impfun"
           )

# create matrix to store percentage nonresponse per question
  perc.nonr <- matrix(NA, nrow=length(hvc), ncol=1)
  rownames(perc.nonr) <- hvc
  colnames(perc.nonr) <- "perc_nonresponse"
  
  for(i in hvc){
    perc.nonr[i, ] <- sum(Main[[i]]==7|Main[[i]]==8)/nrow(Main)*100 
  }
  
#   for(i in 1:length(hvc)){
#   print(table(Main[,hvc[i]]))
# }

# write function that gives missings and proportion of missings   
  prop_mis <- function(x){
  tab <- Main %>%  
      group_by(intnum) %>% 
      dplyr::select(x) %>% 
      table()
  
  if("7" %in% colnames(tab)==F) {
      tab <- cbind(tab, 0)
      colnames(tab)[colnames(tab)==""] <- 7
  } 
    
  if("8" %in% colnames(tab)==F) { 
      tab <- cbind(tab, 0)
      colnames(tab)[colnames(tab)==""] <- 8
  }
  
    mis <- tab[,c("7", "8")]
    mis.tot <-  rowSums(mis)
    int <- rowSums(tab)
    prop.ref <- tab[,c("7")]/int
    prop.dk <- tab[,c("8")]/int
    prop.tot <- mis.tot/int
    assign("tabout", cbind(rownames(mis), int, mis, mis.tot, prop.ref, prop.dk, prop.tot))
    colnames(tabout) <- c("_id", "_nr.int", "_refused", "_dk", "_tot", "_prop.ref", "_prop.dk", "_prop.tot")
    return(tabout)
    }



# Create empty list
  hvs.missings <-list()
# loops over variables and adds Interviewer number, number of interviews, Missings, and Proportions to list
  for(i in hvc){
  hvs.missings[[i]] <- as.data.frame(prop_mis(i))
  }

# turn list into dataframe
  hvs.mis <- as.data.frame(hvs.missings)
# check: do all interviewer numbers match?
  # check <- hvs.mis[,grep("_id", names(hvs.mis))]
  # summary(apply(check, 1, function(x) length(unique(x)) == 1)) # if 0 FALSE, we are good to go!

# Descriptives for proportion missings per interviewer - per variable  
  prop.total <- select(hvs.mis, ipcrtiv._nr.int, ends_with("_prop.tot"))
  prop.total <- prop.total %>%
    tibble::rownames_to_column(., var = "intnum") %>%
    dplyr::rename(num.int = ipcrtiv._nr.int)
  
# calculate the mean/variance/median proportion of missings for every interviewer and assign it
# This is the average (or median/variance) calculated over all the HVS variables
  
  prop.total <- data.frame(lapply(prop.total, function(x) as.numeric(as.character(x))))
  
  prop.total <- prop.total %>%
    mutate(meanmis = rowMeans(select(., -intnum, -num.int)))
```

	The 21 items in module H have an average item-nonresponse ranging from `r round(min(perc.nonr), 2)`% to `r round(max(perc.nonr), 2)`%. Figure \ref{fig:plot_nr_moduleH} shows the distribution of the average proportion of item-nonresponse for all 21 items for each interviewer. It is calculated according to Equation \ref{eq:nr_income} separately for all interviewers and interviewers with at least 10 interviews.

Overall, we can expect the proportions of nonresponse per interviewer to be relatively low, but there might be some exceptions. Looking at all interviewers, we can expect some extreme proportions for interviewers who conducted only one or a few interviews. For a better overview, the distribution of interviewers with at least 10 interviews should therefore also be considered.

```{r nr_moduleH_plot, fig.height = 5, fig.width = 7, fig.cap = paste("\\label{fig:plot_nr_moduleH} Mean proportion of item-nonresponse on items in Module H",  linebreak, "Note: The red line indicates the mean of the proportion. The blue line indicates the median."), fig.scap="Proportion of average item-nonresponse on items in Module H", error=T}

p3 <- ggplot(prop.total, aes(meanmis)) + 
  geom_histogram(fill=ESSColors[4]) +
  labs(x="Proportion (all interviewers)", y = "Frequency") +
  geom_vline(aes(xintercept=mean(meanmis)),
            color=ESSColors[1], size=1) +
  geom_vline(aes(xintercept=median(meanmis)),
            color=ESSColors[5], size=1)

p4 <- ggplot(subset(prop.total, num.int > 9), aes(meanmis)) + 
  geom_histogram(fill=ESSColors[4]) +
  labs(x="Proportion \n(interviewers with at least 10 interviews)", y = "Frequency") +
  geom_vline(aes(xintercept=mean(meanmis)),
            color=ESSColors[1], size=1) +
  geom_vline(aes(xintercept=median(meanmis)),
            color=ESSColors[5], size=1)

plot_grid(p3, p4 + theme(legend.title = element_text(face = "bold"), legend.position = "bottom", legend.direction = "vertical", axis.line.x = element_line()), 
          ncol = 2)
  
  
```

\newpage

For interviewers who conducted many interviews, we expect there to be some, but not a lot of nonresponses. To find unusual proportions of item-nonresponse, we need to zoom in on interviewers who conducted a fair number of interviews, and who have either a very low or a high proportion of nonresponse.

```{r nr_moduleH_unusual, error=T}

  prop.total$group <- as.factor(rep("All interviewers", nrow(prop.total)))
  prop.total.9i <- subset(prop.total, prop.total$num.int>9)
  prop.total.9i$group <- as.factor(rep("Interviewers with at least 10 interviews", nrow(prop.total.9i)))
  prop.total <-bind_rows(prop.total, prop.total.9i)
  
  # Flag outliers
  prop.total <- prop.total %>%
    #tibble::rownames_to_column(var="outlier") #%>%
    group_by(group) %>%
    mutate(is_outlier=ifelse(is_outlier(as.numeric(meanmis)), as.numeric(meanmis), as.numeric(NA))) %>%
    mutate(intnum_out = intnum)
    prop.total$intnum_out[which(is.na(prop.total$is_outlier))] <- as.numeric(NA)
    
# Subset with Interviewers with at least ten interviews and a proportion of item-nonresponse larger than 50%
prop.total.50 <- prop.total %>%
  subset(meanmis >.50 & num.int > 9) %>%
  select(intnum, num.int, meanmis)

# Subset with Interviewers with at least ten interviews and a proportion of item-nonresponse smaller than 1%
prop.total.01 <- prop.total %>%
  subset(meanmis<.01 & num.int > 9) %>%
  select(intnum, num.int, meanmis)
```

Figure \ref{fig:plot_nr_moduleH_unusual} gives an overview of outliers in proportion  of nonresponse, both for the complete sample and for the subset of interviewers who conducted 10 interviews or more. For more details, see table in the annex folder with the proportion of item nonresponse per interviewer on items in Module H ("Prop item nonresponse module H.csv"). We particularly recommend looking at interviewers who have conducted 10 or more interviews and had a proportion of nonresponse larger than 50%. Very little or no nonresponse might also be unusual and worthy of our attention. Those interviewers might be investigated more, but should not be flagged solely on this data.

```{r nr_moduleH_annex, error=T}

Prop_nr_moduleH <- prop.total %>% 
  filter(group == "All interviewers") %>% 
  select(intnum, meanmis, num.int)
Prop_nr_moduleH <- Prop_nr_moduleH[, c("intnum", "meanmis", "num.int")]

write.table(Prop_nr_moduleH,
            "Annex/Prop item nonresponse module H.csv", sep = ";", row.names = F)


```


```{r nr_moduleH_unusual_plot, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot_nr_moduleH_unusual} Mean proportion of item-nonresponse on items in Module H with labelled outliers",  linebreak, "Note: The squares represent the mean of the distribution. Interviewers that are  > 1.5*IQR from the borders of the box are defined as outliers."), fig.scap="Mean proportion of item-nonresponse on items in Module H with labelled outliers", error=T}

ggplot(prop.total, aes(x=group, y=meanmis, fill=group)) + 
    geom_boxplot() +
    stat_summary(fun = mean, geom = "point", shape=23, size=4) +
    scale_fill_manual(values = c(ESSColors[3], ESSColors[4])) +
    geom_text(aes(label=intnum_out), na.rm=TRUE, hjust = -0.3) +
    theme(legend.position="none") + 
    labs(x = "",
         y = "Proportion nonresponse")
```

\newpage

# Observed variance between answers of respondents  {#sec:variance}

## Variance between different interviews: Near duplicates {#sec:duplicates}

Near duplicates refers to the phenomenon of having two or more interviews with almost identical answers to each survey question resulting in an almost perfect corresponding number sequence between two or more completed interviews. The maximum percentage of items on which a respondent's data matches the data of any other respondent in the sample can be calculated to detect near duplicates cases. It can indicate issues in the interviewing quality [@kuriakose2016], but also other issues such as data entry errors. 

Furthermore, high match rates can also be explained by natural survey features [@simmons2016.] However, near duplicates or high match rates tend to be quite rare, and even more so if one or more near duplicates happen to occur within the interview set of a single interviewer. The same argument applies (albeit it is less rare) to near duplicate sequences on the module level.

High match rates within an interviewer could, therefore, be viewed as an indicator of possible issues in the interviewing process (e.g., related to the interaction of interviewer and respondent, interviewer related, or programming and coding errors). Our analysis strategy is based on the approach used by Kuriakose and Robbins [-@kuriakose2016]. This means that to  avoid overestimating the match rate, we have removed variables with missing data for more than 10 per cent of respondents as well as removed any observation where 25 per cent or more of variables were missing. We qualify match rates of 85% or more between interviews as near duplicates and deem them highly unlikely.

```{r duplicates, error=T}
# Dataset with numeric survey items
Main_mis <- Main %>%
  select(idno, intnum,
         nwspol:mcwrkhom,
         testii1:testii9) %>% 
  select_if(is.numeric)

# Replace all non-substantial anwers with missing
Nchar <- Main_mis %>%
  mutate_all(funs(nchar(max(., na.rm = T)))) %>%
  #slice(., 1) %>%
  select(.,-idno)

try(for (i in 1:max(Nchar)) {
  Help <- Nchar[, Nchar[1, ] == i] # all variables with maximum characters==1
  not_applicable <- paste(rep(6, max(Help)), collapse = "")
  refusal <- paste(rep(7, max(Help)), collapse = "")
  dont_know <- paste(rep(8, max(Help)), collapse = "")
  no_answer <- paste(rep(9, max(Help)), collapse = "")

  Main_mis <- Main_mis %>% replace_with_na_at(.vars = names(Help),
                                              condition = ~.x == not_applicable)
  Main_mis <- Main_mis %>% replace_with_na_at(.vars = names(Help),
                                              condition = ~.x %in% names(refusal))
  Main_mis <- Main_mis %>% replace_with_na_at(.vars = names(Help),
                                              condition = ~.x %in% names(dont_know))
  Main_mis <- Main_mis %>% replace_with_na_at(.vars = names(Help),
                                              condition = ~.x %in% names(no_answer))
}, silent = T)

# special case Modul H
Modul_H <- select(Main, ipcrtiv:impfun)
Main_misH <- Main %>%
  select(c(idno, intnum, ipcrtiv:impfun)) %>%
  replace_with_na_at(.vars = names(Modul_H),
                     condition = ~.x %in% c(7, 8, 9))


# Merge datasets
Main_mis <- left_join(Main_mis, Main_misH, by= c("idno", "intnum"))

#
Duplicates <- select_if(Main_mis, colMeans(is.na(Main_mis))<0.1)
Duplicates <- filter(Duplicates, rowMeans(is.na(Duplicates))<0.25)

Duplicates_match <- percentmatchDF_intwer(Duplicates, Duplicates$idno, Duplicates$intnum)
Duplicates_match_iwer <- subset(Duplicates_match, Duplicates_match$intwer1 == Duplicates_match$intwer2)
Duplicates_match_iwer$group <- ifelse(Duplicates_match_iwer$match <= 0.85, "< 85 %", ">= 85 %")

# interviewer with a match rate of 85% and more
duplicates_85 <- filter(Duplicates_match_iwer, group == ">= 85 %")
duplicates_85_vec <- duplicates_85[, "intwer1"]

```

Figure \ref{fig:plot_duplicates} shows the distribution of the match rate as percentage of items in the questionnaire with duplicate answers within the same interviewer. In `r thisCountry`, `r ifelse(length(duplicates_85_vec)==0, "no", length(duplicates_85_vec))` interviewer(s) were found to have interviews with an unlikely match rate of 85% or more. For more details, see table in the annex folder with the match rates per interviewer ("Match rates for near duplicates.csv").

```{r duplicates_annex, error=T}

Match_rates <- Duplicates_match_iwer %>%
  select(id1, id2, intwer1, match) %>%
  dplyr::rename(idno1 = id1, idno2 = id2, intum = intwer1, match_rate = match)

write.table(Match_rates,
            "Annex/Match rates for near duplicates.csv", sep = ";", row.names = F)

```


```{r duplicates_plot, fig.height = 5, fig.width = 7, fig.cap = paste("\\label{fig:plot_duplicates} Percent Match Rates within interviewers",  linebreak, "Note: A match rate of >= 85 $\\%$ is defined as unlikely. The red line indicates this threshold. Unlikely match rates are displayed in a different colour in the figure."), fig.scap="Percent Match Rates within interviewers", error=T}

ggplot(Duplicates_match_iwer, aes(x=match, fill=group)) +
  geom_histogram() +
  scale_fill_manual(values = c(ESSColors[1], ESSColors[4])) +
  geom_vline(aes(xintercept=0.85), color=ESSColors[2]) +
  labs(x="Match rate", y = "Count", fill= "Group")
```

## Low observed variance within interviews: Non-differentiation {#sec:nondiff}

Non-differentiation refers to the tendency to provide the same answer to items in a block of questions [@loosveldt2017]. This response behaviour can be explained by satisficing by the respondents [@chang2009]. However, Loosveldt and Beullens [-@loosveldt2017] were able to observe interviewer effects on the respondent's tendency to choose a response category that is the same as the response category for the previous item. These interviewer effects can, for example, be the result of the absence of challenging the respondent's satisficing tendency by the interviewer, leading the respondents, or completing the questions on behalf of the respondent. This type of undesirable interviewer behaviour can be investigated by looking at the variation in non-differentiation levels between the sets of interviews conducted by a single interviewer. 

In our analysis approach, we measure non-differentiation by calculating the Mulligan Score [@mulligan2001]. It measures the average mean square root of the absolute difference of all answers within an item block for each respondent. For easier interpretation, we have normalized the reference scale and reversed the score, so that 0 indicates the least non-differentiation and 1 indicates the most non-differentiation. We define a Mulligan Score 1.5 times out of the Interquartilerange (IQR) as improbable.

**Non-differentiation results for Module H** 

```{r nondiff, error=T}
# Modul H
# define 7 (Refusal), 8 (Don't know), and 9 (No answer) as Na
Modul_H <- select(Main, ipcrtiv:impfun)
Main_nondiffH <- Main %>%
  select(c(idno, intnum, ipcrtiv:impfun)) %>%
  replace_with_na_at(.vars = names(Modul_H),
                     condition = ~.x %in% c(7, 8, 9))
# normalization (x-min(x))/(max(x)-min(x)); min(x)=1; max(x)=6
Main_nondiffH <- mutate(Main_nondiffH,
                        h1 = ((ipcrtiv-1)/(6-1)), h2 = ((imprich-1)/(6-1)), h3 = ((ipeqopt-1)/(6-1)), h4 = ((ipshabt-1)/(6-1)),
                        h5 = ((impsafe-1)/(6-1)), h6 = ((impdiff-1)/(6-1)), h7 = ((ipfrule-1)/(6-1)), h8 = ((ipudrst-1)/(6-1)),
                        h9 = ((ipmodst-1)/(6-1)), h10 = ((ipgdtim-1)/(6-1)), h11 = ((impfree-1)/(6-1)), h12 = ((iphlppl-1)/(6-1)),
                        h13 = ((ipsuces-1)/(6-1)), h14 = ((ipstrgv-1)/(6-1)), h15 = ((ipadvnt-1)/(6-1)), h16 = ((ipbhprp-1)/(6-1)),
                        h17 = ((iprspot-1)/(6-1)), h18 = ((iplylfr-1)/(6-1)), h19 = ((impenv-1)/(6-1)), h20 = ((imptrad-1)/(6-1)),
                        h21 = ((impfun-1)/(6-1)))
# straighliners defined as MRP (mean root of pairs)
Main_nondiffH <- mutate(Main_nondiffH,
                        h_mrp= ((sqrt(abs(h1-h2)) + sqrt(abs(h1-h3)) + sqrt(abs(h1-h4)) + sqrt(abs(h1-h5)) + sqrt(abs(h1-h6)) +
                                   sqrt(abs(h1-h7)) + sqrt(abs(h1-h8)) + sqrt(abs(h1-h9)) + sqrt(abs(h1-h10)) + sqrt(abs(h1-h11)) +
                                   sqrt(abs(h1-h12)) + sqrt(abs(h1-h13)) + sqrt(abs(h1-h14)) + sqrt(abs(h1-h15)) + sqrt(abs(h1-h16)) +
                                   sqrt(abs(h1-h17)) + sqrt(abs(h1-h18)) + sqrt(abs(h1-h19)) + sqrt(abs(h1-h20)) + sqrt(abs(h1-h21)) +
                                   
                                   sqrt(abs(h2-h3)) + sqrt(abs(h2-h4)) + sqrt(abs(h2-h5)) + sqrt(abs(h2-h6)) +
                                   sqrt(abs(h2-h7)) + sqrt(abs(h2-h8)) + sqrt(abs(h2-h9)) + sqrt(abs(h2-h10)) + sqrt(abs(h2-h11)) +
                                   sqrt(abs(h2-h12)) + sqrt(abs(h2-h13)) + sqrt(abs(h2-h14)) + sqrt(abs(h2-h15)) + sqrt(abs(h2-h16)) +
                                   sqrt(abs(h2-h17)) + sqrt(abs(h2-h18)) + sqrt(abs(h2-h19)) + sqrt(abs(h2-h20)) + sqrt(abs(h2-h21)) +
                                   
                                   sqrt(abs(h3-h4)) + sqrt(abs(h3-h5)) + sqrt(abs(h3-h6)) +
                                   sqrt(abs(h3-h7)) + sqrt(abs(h3-h8)) + sqrt(abs(h3-h9)) + sqrt(abs(h3-h10)) + sqrt(abs(h3-h11)) +
                                   sqrt(abs(h3-h12)) + sqrt(abs(h3-h13)) + sqrt(abs(h3-h14)) + sqrt(abs(h3-h15)) + sqrt(abs(h3-h16)) +
                                   sqrt(abs(h3-h17)) + sqrt(abs(h3-h18)) + sqrt(abs(h3-h19)) + sqrt(abs(h3-h20)) + sqrt(abs(h3-h21)) +
                                   
                                   sqrt(abs(h4-h5)) + sqrt(abs(h4-h6)) +
                                   sqrt(abs(h4-h7)) + sqrt(abs(h4-h8)) + sqrt(abs(h4-h9)) + sqrt(abs(h4-h10)) + sqrt(abs(h4-h11)) +
                                   sqrt(abs(h4-h12)) + sqrt(abs(h4-h13)) + sqrt(abs(h4-h14)) + sqrt(abs(h4-h15)) + sqrt(abs(h4-h16)) +
                                   sqrt(abs(h4-h17)) + sqrt(abs(h4-h18)) + sqrt(abs(h4-h19)) + sqrt(abs(h4-h20)) + sqrt(abs(h4-h21)) +
                                   
                                   sqrt(abs(h5-h6)) +
                                   sqrt(abs(h5-h7)) + sqrt(abs(h5-h8)) + sqrt(abs(h5-h9)) + sqrt(abs(h5-h10)) + sqrt(abs(h5-h11)) +
                                   sqrt(abs(h5-h12)) + sqrt(abs(h5-h13)) + sqrt(abs(h5-h14)) + sqrt(abs(h5-h15)) + sqrt(abs(h5-h16)) +
                                   sqrt(abs(h5-h17)) + sqrt(abs(h5-h18)) + sqrt(abs(h5-h19)) + sqrt(abs(h5-h20)) + sqrt(abs(h5-h21)) +
                                   
                                   sqrt(abs(h6-h7)) + sqrt(abs(h6-h8)) + sqrt(abs(h6-h9)) + sqrt(abs(h6-h10)) + sqrt(abs(h6-h11)) +
                                   sqrt(abs(h6-h12)) + sqrt(abs(h6-h13)) + sqrt(abs(h6-h14)) + sqrt(abs(h6-h15)) + sqrt(abs(h6-h16)) +
                                   sqrt(abs(h6-h17)) + sqrt(abs(h6-h18)) + sqrt(abs(h6-h19)) + sqrt(abs(h6-h20)) + sqrt(abs(h6-h21)) +
                                   
                                   sqrt(abs(h7-h8)) + sqrt(abs(h7-h9)) + sqrt(abs(h7-h10)) + sqrt(abs(h7-h11)) +
                                   sqrt(abs(h7-h12)) + sqrt(abs(h7-h13)) + sqrt(abs(h7-h14)) + sqrt(abs(h7-h15)) + sqrt(abs(h7-h16)) +
                                   sqrt(abs(h7-h17)) + sqrt(abs(h7-h18)) + sqrt(abs(h7-h19)) + sqrt(abs(h7-h20)) + sqrt(abs(h7-h21)) +
                                   
                                   sqrt(abs(h8-h9)) + sqrt(abs(h8-h10)) + sqrt(abs(h8-h11)) +
                                   sqrt(abs(h8-h12)) + sqrt(abs(h8-h13)) + sqrt(abs(h8-h14)) + sqrt(abs(h8-h15)) + sqrt(abs(h8-h16)) +
                                   sqrt(abs(h8-h17)) + sqrt(abs(h8-h18)) + sqrt(abs(h8-h19)) + sqrt(abs(h8-h20)) + sqrt(abs(h8-h21)) +
                                   
                                   sqrt(abs(h9-h10)) + sqrt(abs(h9-h11)) +
                                   sqrt(abs(h9-h12)) + sqrt(abs(h9-h13)) + sqrt(abs(h9-h14)) + sqrt(abs(h9-h15)) + sqrt(abs(h9-h16)) +
                                   sqrt(abs(h9-h17)) + sqrt(abs(h9-h18)) + sqrt(abs(h9-h19)) + sqrt(abs(h9-h20)) + sqrt(abs(h9-h21)) +
                                   
                                   sqrt(abs(h10-h11)) +
                                   sqrt(abs(h10-h12)) + sqrt(abs(h10-h13)) + sqrt(abs(h10-h14)) + sqrt(abs(h10-h15)) + sqrt(abs(h10-h16)) +
                                   sqrt(abs(h10-h17)) + sqrt(abs(h10-h18)) + sqrt(abs(h10-h19)) + sqrt(abs(h10-h20)) + sqrt(abs(h10-h21)) +
                                   
                                   sqrt(abs(h11-h12)) + sqrt(abs(h11-h13)) + sqrt(abs(h11-h14)) + sqrt(abs(h11-h15)) + sqrt(abs(h11-h16)) +
                                   sqrt(abs(h11-h17)) + sqrt(abs(h11-h18)) + sqrt(abs(h11-h19)) + sqrt(abs(h11-h20)) + sqrt(abs(h11-h21)) +
                                   
                                   sqrt(abs(h12-h13)) + sqrt(abs(h12-h14)) + sqrt(abs(h12-h15)) + sqrt(abs(h12-h16)) +
                                   sqrt(abs(h12-h17)) + sqrt(abs(h12-h18)) + sqrt(abs(h12-h19)) + sqrt(abs(h12-h20)) + sqrt(abs(h12-h21)) +
                                   
                                   sqrt(abs(h13-h14)) + sqrt(abs(h13-h15)) + sqrt(abs(h13-h16)) +
                                   sqrt(abs(h13-h17)) + sqrt(abs(h13-h18)) + sqrt(abs(h13-h19)) + sqrt(abs(h13-h20)) + sqrt(abs(h13-h21)) +
                                   
                                   sqrt(abs(h14-h15)) + sqrt(abs(h14-h16)) +
                                   sqrt(abs(h14-h17)) + sqrt(abs(h14-h18)) + sqrt(abs(h14-h19)) + sqrt(abs(h14-h20)) + sqrt(abs(h14-h21)) +
                                   
                                   sqrt(abs(h15-h16)) +
                                   sqrt(abs(h15-h17)) + sqrt(abs(h15-h18)) + sqrt(abs(h15-h19)) + sqrt(abs(h15-h20)) + sqrt(abs(h15-h21)) +
                                   
                                   sqrt(abs(h16-h17)) + sqrt(abs(h16-h18)) + sqrt(abs(h16-h19)) + sqrt(abs(h16-h20)) + sqrt(abs(h16-h21)) +
                                   
                                   sqrt(abs(h17-h18)) + sqrt(abs(h17-h19)) + sqrt(abs(h17-h20)) + sqrt(abs(h17-h21)) +
                                   
                                   sqrt(abs(h18-h19)) + sqrt(abs(h18-h20)) + sqrt(abs(h18-h21)) +
                                   
                                   sqrt(abs(h19-h20)) + sqrt(abs(h19-h21)) +
                                   
                                   sqrt(abs(h20-h21)))/210))
                        
# Normalization and reverse coding of Mulligan Score (Score between 0...least straightlining and 1...most straighlining)
Main_nondiffH <- mutate(Main_nondiffH, 
                        h_mulligan = ((h_mrp - max(Main_nondiffH$h_mrp, na.rm = T))/
                                        ((min(Main_nondiffH$h_mrp, na.rm = T)-max(Main_nondiffH$h_mrp, na.rm = T)))))


# average Mulligan Score for each interviewer
Mulligan_H_all <- Main_nondiffH %>%
  group_by(intnum) %>%
  summarise(avg=mean(h_mulligan, na.rm = TRUE)) %>%
  mutate(group = "All interviewers")
# average interviwer speed for interviewers with at least 4 interviews
Mulligan_H_4 <- Main_nondiffH %>%
  group_by(intnum) %>%
  filter(n() > 3) %>%
  summarise(avg=mean(h_mulligan, na.rm = TRUE)) %>%
  mutate(group = "Interviewers with at least 4 interviews")

Mulligan <- bind_rows(Mulligan_H_all, Mulligan_H_4)

  # Flag outliers
  Mulligan <- Mulligan %>%
    mutate(is_outlier=ifelse(is_outlier(as.numeric(avg)), as.numeric(avg), as.numeric(NA))) %>%
    mutate(intnum_out = intnum)
    Mulligan$intnum_out[which(is.na(Mulligan$is_outlier))] <- as.numeric(NA)



# # Define outlier in h_mulligan
# Main_nondiffH <- Main_nondiffH %>%
#   #tibble::rownames_to_column(var="outlier") #%>%
#   mutate(is_outlier=ifelse(is_outlier(h_mulligan), h_mulligan, as.numeric(NA))) %>%
#   mutate(intnum_out = intnum)
# Main_nondiffH$intnum_out[which(is.na(Main_nondiffH$is_outlier))] <- as.numeric(NA)


```

Figure \ref{fig:plot_nondiff} shows the average Mulligan Score for each interview and interviewers with at least four interviews for module H. We made this differentiation, because the probability that outliers are incidental findings is lower for interviewers with at least four interviews. Interviewers that are defined as outliers are labelled in the figure. For more details, see table in the annex folder with the average Mulligan Score for non-differentiation in module H per interviewer ("Non-differentiation in module H per interviewer.csv").

```{r nondiff_annex, error=T}

write.table(Mulligan_H_all[,c("intnum", "avg")] %>% dplyr::rename(avg_mulligan = avg),
            "Annex/Match rates for near duplicates.csv", sep = ";", row.names = F)

```



```{r nondiff_plot, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot_nondiff} Mulligan scores for Module H per interviewer",  linebreak, "Note: The nondifferentiation index (Mulligan Score) ranges from 0 (indicating the least non-differentiation) to 1 (indicating the most differentiation). Interviewers that are  > 1.5*IQR from the borders of the box are labelled."), fig.scap = "Mulligan scores for Module H per interviewer", error=T}

ggplot(Mulligan, aes(x=group, y=avg, fill=group)) + 
    geom_boxplot() +
    stat_summary(fun = mean, geom = "point", shape=23, size=4) +
    scale_fill_manual(values = c(ESSColors[3], ESSColors[4])) +
    geom_text(aes(label=intnum_out), na.rm=TRUE, hjust = -0.3) +
    theme(legend.position="none") + 
    labs(x = "",
         y = "Average Mulligan Score per interviewer")
```

## Variance within and between interviews: Difference in latent variables {#sec:latentvar}

In this section, we investigate the impact of interviewers on latent variables from item batteries in the questionnaire. We look at the answer patterns to set of items within an interview and compare it to the overall dimension built by the answers pattern the other respondents. The extent to which the differences of the answers of respondents is related to allocation within an interviewer can ascertain the effect interviewers have on answers and can help identify issues regarding interviewer behaviour.

For this purpose, we run a categorical principal component analysis (CatPCA) over a selected battery of items. The categorical principal component analysis is conducted on a set of categorical variables. It allows analysing the relationship between multiple variables while reducing the dimensionality of the data to facilitate interpretation. The items selected for the analysis correspond to the battery of items on trust in institutions from section B of the ESS core questionnaire (trstprl, trstlgl, trstplc, trstplt, trstprt, trstep, and trstun) for which we can expect a dimension ranging from 'no trust at all' to 'complete trust'.

```{r latentvar, error=T}
#set variables necessary to be kept for analysis, this should be the standard set
keptvars<-c("idno", "cntry", "intnum")

#set variables for battery to be analyzed (example)
trust <-c("trstprl", "trstlgl", "trstplc", "trstplt", "trstprt" ,"trstep", "trstun")

#Minimum number of interviews needed to be completed for analysis
if(max(inc.mis.all$num.int)>15) {	
mnint <- 14	
} else { 	
mnint <- 9	
}

CatPCAall <- CatPCA_scntry(Main, trust, keptvars, mnint)
CatPCA <- na.omit(CatPCAall)

Mscores_descr <- psych::describe(CatPCA$m_intscore, quant=c(.05,.95)) %>%
  select(mean, median, sd, Q0.05, Q0.95)
SDscores_descr <- psych::describe(CatPCA$sd_intscore, quant=c(.05,.95)) %>%
  select(mean, median, sd, Q0.05, Q0.95)

  # Flag outliers in mean scores
  CatPCA <- CatPCA %>%
    mutate(outlier_m=ifelse(m_intscore > (Mscores_descr$mean + Mscores_descr$sd*2) | m_intscore < (Mscores_descr$mean + Mscores_descr$sd*-2)  , as.numeric(m_intscore), as.numeric(NA))) %>%
    mutate(intnum_out_m = intnum)
    CatPCA$intnum_out_m[which(is.na(CatPCA$outlier_m))] <- as.numeric(NA)
    CatPCA$is_outlier_m <- ifelse(is.na(CatPCA$outlier_m), "No", "Yes")
    
      # Flag outliers in sd of scores
  CatPCA <- CatPCA %>%
    mutate(outlier_sd=ifelse(sd_intscore > (SDscores_descr$mean + SDscores_descr$sd*2) | sd_intscore < (SDscores_descr$mean + SDscores_descr$sd*-2), as.numeric(sd_intscore), as.numeric(NA))) %>%
    mutate(intnum_out_sd = intnum)
    CatPCA$intnum_out_sd[which(is.na(CatPCA$outlier_sd))] <- as.numeric(NA)
    CatPCA$is_outlier_sd <- ifelse(is.na(CatPCA$outlier_sd), "No", "Yes")
```

To estimate the effect that interviewers have on the answers of respondents, we calculate (a) the mean of component scores of the first component across interviews conducted by the same interviewer and (b) the standard deviations of those scores. We limit the analysis to interviewers with at least 15 interviews completed, as suggested by the literature [@blasius2018], if the maximum number of interviews per interviewer in the dataset is greater than 15. Otherwise, we limit the analysis to interviewers with at least 10 interviews.

**A.	Mean of Component Scores (between-interviewers variance)**

The component scores indicate the distance of each case from to the overall estimated dimension (centered at 0). By calculating the mean of the component scores per interviewer, we can estimate how strongly the answers of respondents interviewed by each interviewer related to the overall component. Figure \ref{fig:plot1_latentvar}, shows the distribution of the mean of the component scores per interviewer. Means that are very different to zero indicate that respondents allocated to those interviewers answered very differently to the battery on trust in institutions compared to the whole sample. For example, a very high mean would indicate that respondents from interviewer X tend to show much more trust in institutions compared to the overall trust of respondents in the sample. To facilitate the overview of results, we define and present outliers with  2 standard deviations from the interviewers' mean of means. 

```{r latentvar_plot1, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot1_latentvar} Mean of component scores across interviews",  linebreak, "Note: Interviewers whose mean score exceeds  2 standard deviations from the mean across interviewers are highlighted."), fig.scap="Mean of component scores across interviews", error=T}
ggplot(CatPCA, aes(m_intscore, as.factor(intnum)))  + 
  geom_point(aes(colour = CatPCA$is_outlier_m)) +
  labs(x = "Mean CatPCA score loading across interviews",
       y = "Interviewers",
       color =  "Outlier with  2 standard \ndeviations from the mean") +
  geom_vline(xintercept = Mscores_descr$mean, color = wes_palette(n=1, name = "Zissou1")) +
  geom_vline(xintercept = Mscores_descr$mean + Mscores_descr$sd*2) +
  geom_vline(xintercept = Mscores_descr$mean + Mscores_descr$sd*-2) +
  scale_colour_manual(values = c("No" = "black",
                                  "Yes" = ESSColors[2])) +
  geom_text(aes(label=intnum_out_m), na.rm=TRUE, vjust = 1.5)
```
**B.	Standard Deviation of Component Scores (within-interviewer variance)**

It is also important to observe how different or similar the answers of respondents interviewed by the same interviewer are. By calculating the standard deviation of the component scores per interviewer, we can estimate the similarity of the answers of respondents interviewed by one interviewer. Figure \ref{fig:plot2_latentvar} shows the distributions of the standard deviation of the average scores from the interviews within each interviewer. Large standard deviations indicate that answers of respondents interviewed by the same interviewer are very different with regards to the principal component. In contrast, small standard deviations indicate that answers of respondents were very similar. For example, very small standard deviations of component scores would mean that most respondents from interviewer X shared very similar trust in institutions compared to views of the whole sample. To facilitate the overview, we define and present outliers with  2 standard deviations from the interviewers' mean of standard deviations.

```{r latentvar_plot2, fig.height = 9, fig.width = 7, fig.cap = paste("\\label{fig:plot2_latentvar} Standard deviation of component scores across interviews", "Note: Interviewers whose mean score exceeds  2 standard deviations from the mean standard deviation across interviewers are highlighted."), fig.scap="Standard deviation of component scores across interviews", error=T}
ggplot(CatPCA, aes(sd_intscore, as.factor(intnum)))  + 
  geom_point(aes(colour = CatPCA$is_outlier_sd)) +
  labs(x = "Standard Deviation of CatPCA score loading across interviews",
       y = "Interviewers",
       color =  "Outlier with  2 standard \ndeviations from the mean") +
  geom_vline(xintercept = SDscores_descr$mean, color = wes_palette(n=1, name = "Zissou1"))+
  geom_vline(xintercept = SDscores_descr$mean + SDscores_descr$sd*2) +
  geom_vline(xintercept = SDscores_descr$mean + SDscores_descr$sd*-2) +
  scale_colour_manual(values = c("No" = "black",
                                  "Yes" = ESSColors[2])) +
  geom_text(aes(label=intnum_out_sd), na.rm=TRUE, vjust = 1.5)

```

When interpreting these results, we recommend looking at both the means and standard deviation of component scores to get a better picture of the answer patterns of respondents within a specific interviewer. For more details, please see the table in the annexe folder with means and standard deviation of the component scores ("Latent variable.csv").

```{r latentvar_annex, error=T}

write.table(CatPCA[,c("intnum", "m_intscore", "sd_intscore")],
            "Annex/Latent variable.csv", sep = ";", row.names = F)


```


Please note that these indicators have been applied by researchers to detect highly unlikely answer patterns in the data being produced by a single interviewer [@blasius2018]. However, the analysis does not allow us to derive the causes of outliers (as it is the case for most indicators in this report). It is necessary to conduct further investigation on flagged interviewer in the field in order to explain the reasons for any observed issues. It is highly encouraged to conduct back-check and close monitoring of flagged interviewers.

\newpage

# References
